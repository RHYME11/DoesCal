{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f23e002-e94a-44f7-ab1b-c6ce67c0bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdfplumber\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Font, PatternFill, Border, Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115c719-6fa4-45d2-b840-05228b636518",
   "metadata": {},
   "source": [
    "## Step 1: Fill Excel \"DoesCal.xlsx\" (Manual) :\n",
    "    In Sheet \"Initial\", fill all cells in yellow with fixed units.\n",
    "\n",
    "## Step 2: Save PACE4 results in Folder \"PACE4\" (Manual):\n",
    "    Make sure the beam energy for PACE4 is same as the one in Excel Sheet \"Initial\"\n",
    "\n",
    "## Step 3: Run the code to copy info from PACE4 result to \"DoesCal.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b923e5-f4b3-410f-8043-799853298a49",
   "metadata": {},
   "source": [
    "### Code(Extract_CompoundInf): extract Compound Info from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f30c4b-e0b6-4b8f-82d6-02d289ef6174",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Extract_CompoundInf(text):\n",
    "    # Return Values:\n",
    "    Coulomb_Barrier = -1\n",
    "    Center_Mass = -1\n",
    "    Recoil_Energy = -1\n",
    "    Beam_Energy = -1\n",
    "    Compound_A = -1\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    # loop all lines in this text(page)\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"Bass fusion xsection for E = \" in line:\n",
    "            match = re.search(r'Bass fusion xsection for E = (\\d+(\\.\\d+)?)\\s*MeV', line)\n",
    "            if match:\n",
    "                Beam_Energy = float(match.group(1))\n",
    "                continue\n",
    "        if \"Barrier height\" in line:\n",
    "            match = re.search(r'Barrier height is (\\d+(\\.\\d+)?)\\s*MeV', line)\n",
    "            if match:\n",
    "                Coulomb_Barrier = float(match.group(1))\n",
    "                continue\n",
    "        if \"Center of mass energy (MeV)\" in line:\n",
    "            match = re.search(r'Center of mass energy \\(MeV\\)\\s*(\\d+(\\.\\d+)?)', line)\n",
    "            if match:\n",
    "                Center_Mass = float(match.group(1))\n",
    "                continue\n",
    "        if \"Compound nucleus recoil energy (MeV)\" in line:\n",
    "            match = re.search(r'Compound nucleus recoil energy \\(MeV\\)\\s*(\\d+(\\.\\d+)?)', line)\n",
    "            if match:\n",
    "                Recoil_Energy = float(match.group(1))\n",
    "                break\n",
    "        if \"Compound nucleus \" in line and Compound_A < 0:\n",
    "            columns = line.split()\n",
    "            Compound_A = float(columns[-1])\n",
    "\n",
    "    if Beam_Energy<0:\n",
    "        print(\"Beam energy NOT Found\")\n",
    "    if Coulomb_Barrier<0:\n",
    "        print(\"Barrier height NOT Found\")\n",
    "    if Center_Mass<0:\n",
    "        print(\"Center of mass energy NOT Found\")\n",
    "    if Recoil_Energy<0:\n",
    "        print(\"Compound nucleus recoil energy NOT Found\")\n",
    "    if Compound_A<0:\n",
    "        print(\"Compound nucleus info NOT Found\")\n",
    "    \n",
    "        \n",
    "    return Beam_Energy, Coulomb_Barrier, Center_Mass, Recoil_Energy, Compound_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce3598a-3c49-41fc-836d-c585ad5c8846",
   "metadata": {},
   "source": [
    "### Code(Extract_ProductInf): extract Production Info from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "532058f5-b1cb-4242-b286-bf303f9ba82f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Extract_ProductInf(pdf):\n",
    "    start_flag = False \n",
    "    end_flag = False\n",
    "    Production_Inf = []\n",
    "    for page_num, page in enumerate(pdf.pages[1:]):\n",
    "        if start_flag and end_flag: break\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            lines = text.split('\\n')\n",
    "            for i, line in enumerate(lines):\n",
    "                if \"Yields of residual nuclei\" in line: \n",
    "                    start_flag = True\n",
    "                    continue\n",
    "                if \"Angular distribution results\" in line: \n",
    "                    end_flag = True\n",
    "                    break\n",
    "                if start_flag and not end_flag:\n",
    "                    Production_Inf.append(line.split())\n",
    "    if not Production_Inf:\n",
    "        print(\"Yields of residual nuclei NOT Found\")\n",
    "    return Production_Inf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e23e8f-0c02-40aa-8c11-362270f494f8",
   "metadata": {},
   "source": [
    "### Code(Filter_Inf): filter Production Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a36d49-989a-414b-aff2-b60206cf8d8c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Filter_Inf(Production):\n",
    "    # If production cross pages, there will be line written in \"Production\" with one element which returns page number\n",
    "    # So we need to delete it first\n",
    "    Production = [row for row in Production if len(row) > 1]\n",
    "\n",
    "    # Take out the last line which contains total information for the reaction\n",
    "    # Then delete it from \"Production\"\n",
    "    Total = Production[-1]\n",
    "    Production = Production[:-1]\n",
    "\n",
    "    # Add \"isotop for the Column name\"\n",
    "    Production[0].insert(3, \"isotope\")\n",
    "    \n",
    "    # Only Record Z, N, A, isotope, xsection information into Excel\n",
    "    # And convert all values to int or float\n",
    "    Production_Record = [[row[0], row[1], row[2], row[3], row[6]] for row in Production]\n",
    "    for row in Production_Record[1:]:\n",
    "        row[0] = int(row[0])  # Convert Z to int\n",
    "        row[1] = int(row[1])  # Convert N to int\n",
    "        row[2] = int(row[2])  # Convert A to int\n",
    "        row[4] = float(row[4])  # Convert x-section(mb) to float\n",
    "    \n",
    "    return Total, Production_Record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e62c8d6-f23a-4d80-b19b-d3160c84d82c",
   "metadata": {},
   "source": [
    "### Code(Write_Excel): write info to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22823643-93dc-4fde-aaa0-e8ec862384bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Write_Excel(Production_Record, Total, file_path, Beam_Energy=0, Recoil_Energy=0, Compound_A = 0):\n",
    "    #================== Update \"Initial\" sheet ================#\n",
    "    # Load the existing workbook and the \"Initial\" sheet\n",
    "    workbook = load_workbook(file_path)\n",
    "    existing_df = pd.read_excel(file_path, sheet_name=\"Initial\", engine='openpyxl')\n",
    "    \n",
    "    # Update the existing DataFrame with recoil energy and total x-sec for the current beam energy\n",
    "    row_index = existing_df[existing_df[\"Beam Energy (MeV)\"] == Beam_Energy].index[0]\n",
    "    existing_df.at[row_index, \"Recoil Energy (MeV)\"] = Recoil_Energy\n",
    "    existing_df.at[row_index, \"Total xsec (mb)\"] = float(Total[-1])\n",
    "    thickness = existing_df.at[row_index,\"Target layer (um)\"]\n",
    "\n",
    "    # Write the updated DataFrame back to the \"Initial\" sheet\n",
    "    existing_worksheet = workbook[\"Initial\"] \n",
    "    for row in range(len(existing_df)):\n",
    "        for col in range(len(existing_df.columns)):\n",
    "            existing_worksheet.cell(row=row + 2, column=col + 1, value=existing_df.iat[row, col])  # +2 to account for header\n",
    "    # Save the workbook after updating the existing sheet\n",
    "    workbook.save(file_path)\n",
    "\n",
    "    #================== Create new sheet for PACE4 result ================#\n",
    "    # Convert the first row as headers and the rest recorded into DataFrame\n",
    "    df = pd.DataFrame(Production_Record[1:], columns=Production_Record[0])\n",
    "    \n",
    "    # Create a new row for the DataFrame based on Total\n",
    "    total_row = pd.DataFrame({\n",
    "        'Z': [Total[0]],  # The first element of Total in 'Z' column\n",
    "        'x-section(mb)': [float(Total[-1])]  # The last element of Total in 'x-section(mb)' column\n",
    "    })\n",
    "    \n",
    "    # Append the total_row to the DataFrame\n",
    "    df = pd.concat([df, total_row], ignore_index=True)\n",
    "\n",
    "    # Insert a new column \"Recoil Energy(MeV)\" after \"x-section(mb)\"\n",
    "    df.insert(df.columns.get_loc('x-section(mb)') + 1, 'Recoil_E(MeV)', \n",
    "              df['A'].apply(lambda A: Recoil_Energy / Compound_A * A))\n",
    "    \n",
    "    # Create a new sheet name based on Beam Energy\n",
    "    new_sheet_name = f'{int(thickness)}um_{int(Beam_Energy)}MeV'\n",
    "\n",
    "    # Now create the new sheet with the updated DataFrame\n",
    "    with pd.ExcelWriter(file_path, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "        df.to_excel(writer, sheet_name=new_sheet_name, index=False)\n",
    "\n",
    "    # Reopen the workbook to apply formatting\n",
    "    workbook = load_workbook(file_path)\n",
    "\n",
    "    # Set column width and alignment for the new sheet\n",
    "    worksheet = workbook[new_sheet_name]\n",
    "    for column in worksheet.columns:\n",
    "        column_letter = column[0].column_letter\n",
    "        worksheet.column_dimensions[column_letter].width = 16\n",
    "        for cell in column:  # Align each cell in the column\n",
    "            cell.alignment = Alignment(horizontal='right')\n",
    "   \n",
    "    # Final save\n",
    "    workbook.save(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0161a1-7f0f-45cc-9f72-3f7de9c86367",
   "metadata": {},
   "source": [
    "### Code(RWProcess): Read PDF and Write EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd818f6-05ab-4513-b136-ceba45b4f880",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def RWProcess(pdf_path, excel_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # Extract basic information for this reaction\n",
    "        page = pdf.pages[0]\n",
    "        text = page.extract_text()\n",
    "        Beam_Energy, Coulomb_Barrier, Center_Mass, Recoil_Energy, Compound_A = Extract_CompoundInf(text)\n",
    "        # Extract info for productions from the reaction\n",
    "        Production = Extract_ProductInf(pdf)\n",
    "\n",
    "    # Filter Production info to write them into Spreadsheet\n",
    "    Total, Production_Record = Filter_Inf(Production)\n",
    "\n",
    "    # Write Production Info into Excel:\n",
    "    Write_Excel(Production_Record, Total, excel_path, Beam_Energy, Recoil_Energy, Compound_A)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2355d52-b95f-4aee-a4ef-b5ab5f330269",
   "metadata": {},
   "source": [
    "### Code(RWPACE4): loop PACE4 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "324098e1-a7b7-4967-9e4d-7abdfb1477ea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def RWPACE4(folder_path, excel_path):\n",
    "    for pdf_file in os.listdir(folder_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, pdf_file)\n",
    "            RWProcess(pdf_path, excel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afddbcc5-d39e-4a09-bbe0-86f77b1d8f89",
   "metadata": {},
   "source": [
    "## Step 4: Extract Half-Lives\n",
    "### 4.1 Read half-life information from NNDC :\n",
    "1. Go to Nuclear Levels and Gammas Search;\n",
    "2. Give the range for Z or A or N to search the result (I usually set half-live range > 1 sec);\n",
    "3. Save the result page as PDF (Right click -> choose print -> Save as PDF);\n",
    "\n",
    "* No space in any path\n",
    "\n",
    "### 4.2 Extract half-lives:\n",
    "1. Only write the half-life info into the .txt file same name as .pdf file (ONE TIME Operation!!!! Unless you want to update the old one)\n",
    "2. Extract the half-lives from .txt file, which is faster than reading .pdf file;\n",
    "3. Add half-life info to isotopes saved in the Excel sheet created in Step 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8f4380-f4c6-47f5-9c2b-99a2333db9a4",
   "metadata": {},
   "source": [
    "### Code(Convert_PDF_to_TXT): convert t1/2 PDF to TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6af9e8-cb38-49bc-8df1-8acff1629073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert_PDF_to_TXT(pdf_path, flag_overwrite = False):\n",
    "    # Get the base name of the PDF file (without the extension) using string operations\n",
    "    base_name = pdf_path.split('/')[-1].replace('.pdf', '')\n",
    "    # Create the output TXT file name\n",
    "    txt_path = pdf_path.replace('.pdf', '.txt')\n",
    "    \n",
    "    # if txt file exists and don't need to be replaced, return empty\n",
    "    if os.path.exists(txt_path) and flag_overwrite:\n",
    "        return\n",
    "    # if txt file doesn't exist or you want to overwrite it\n",
    "    else:\n",
    "        # Open the PDF file\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            text_to_write = []\n",
    "            capture_text = False # will be \"True\" when detect \"Nucleus E level(keV) Jπ T 1/2\" where start extracting info\n",
    "            # Iterate through each page\n",
    "            for page in pdf.pages:\n",
    "                # Extract the text from the page\n",
    "                text = page.extract_text() \n",
    "                # Split the text into lines\n",
    "                lines = text.split('\\n')\n",
    "                for line in lines:\n",
    "                    # Skip the unwanted header and footer lines\n",
    "                    #if \"page\" in line.lower() and \",\" in line and (\"AM\" in line or \"PM\" in line):\n",
    "                    if \"AM\" in line or \"PM\" in line:\n",
    "                        continue\n",
    "                    if \"https://www.nndc.bnl.gov\" in line:\n",
    "                        continue     \n",
    "                    # Start capturing text after the target start line\n",
    "                    if \"Nucleus E level(keV) Jπ T 1/2\" in line:\n",
    "                        capture_text = True\n",
    "                        continue\n",
    "                    # Stop capturing text after the target end line\n",
    "                    if \"Gamma Information\" in line:\n",
    "                        capture_text = False\n",
    "                        continue\n",
    "                    if \"≥\" in line or \">\" in line:\n",
    "                        continue\n",
    "                    if \"eV\" in line:\n",
    "                        continue\n",
    "                    # Capture the text\n",
    "                    if capture_text:\n",
    "                        text_to_write.append(line)\n",
    "        # Write the captured text to the dynamically named txt file\n",
    "        with open(txt_path, \"w\") as output_file:\n",
    "            output_file.write(\"\\n\".join(text_to_write))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c654f7c-565c-447f-8697-e345bfb2d778",
   "metadata": {},
   "source": [
    "### mini Code(parse_t_half): parse t1/2 info in txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ee8f72-0e7a-4e3c-8547-df2da3766df6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ============= Function to parse the t_half value into t_value + t_unit ==============#\n",
    "# the input \"t_half\" should have one character (no-digit) part\n",
    "def parse_t_half(t_half):\n",
    "    # if t1/2 = stable, will return the age of the universe\n",
    "    if t_half.upper() == \"STABLE\":\n",
    "        return 1.4e10, \"y\"\n",
    "    matches = re.findall(r'(\\d+(?:\\.\\d+)?(?:e[-+]?\\d+)?)\\s*([a-zA-Z]+)', t_half)\n",
    "    # Initialize variables for the extracted values\n",
    "    t_value = -1\n",
    "    t_unit = None\n",
    "    # If matches are found, assign the number and unit\n",
    "    if matches:\n",
    "        t_value = float(matches[0][0])  # First number found\n",
    "        t_unit = matches[0][1]    # Corresponding unit\n",
    "    return t_value, t_unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04863078-b55e-4434-8760-df1c4ade7e9a",
   "metadata": {},
   "source": [
    "### Code(Extract_HalfLife): Extract A, nucleus_name, t1/2_value and t1/2_unit into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "678715fa-266a-41cb-92b2-85d55484dc71",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ============= Function to extract t1/2 from txt ==============#\n",
    "# extracted_data = [A,\"nucleus_name\", t1/2, \"unit\"]\n",
    "def Extract_HalfLife(txt_path):\n",
    "    # Open the existing TXT file and process it\n",
    "    with open(txt_path, \"r\") as input_file:\n",
    "        extracted_data = []\n",
    "        # Skip the first line (header)\n",
    "        next(input_file)\n",
    "        for line in input_file:\n",
    "            # Skip any empty lines\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            # Split the line into columns\n",
    "            columns = line.split()\n",
    "            # Extract Nucleus (separated into number and letters, like \"1H\" to \"1\" and \"H\")\n",
    "            nucleus_full = columns[0]\n",
    "            nucleus_number = ''.join([char for char in nucleus_full if char.isdigit()])\n",
    "            nucleus_letters = ''.join([char for char in nucleus_full if char.isalpha()])\n",
    "            # Extract and parse T 1/2\n",
    "            t_half = ' '.join(columns[3:])\n",
    "            value, unit = parse_t_half(t_half)\n",
    "            if value > 0:\n",
    "                # Append the extracted data as a tuple\n",
    "                extracted_data.append((float(nucleus_number), nucleus_letters, value, unit))\n",
    "        return extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b59ac1-f211-45d2-9d52-fd37cf97f84e",
   "metadata": {},
   "source": [
    "### mini Code(HalfLife_Unit_Factor): scaling factor to convert t1/2 in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a2aa4de-0693-4afa-ba7b-f30e3044c340",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#============= convert all half-lives to seconds =============#\n",
    "def HalfLife_Unit_Factor(unit):\n",
    "    fac = 0\n",
    "    if unit == \"s\":\n",
    "        fac = 1;\n",
    "    if unit == \"m\":\n",
    "        fac = 60;\n",
    "    if unit == \"h\":\n",
    "        fac = 60*60;\n",
    "    if unit == \"d\":\n",
    "        fac = 24*60*60;\n",
    "    if unit == \"y\":\n",
    "        fac = 365*24*60*60;\n",
    "    return fac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d318f57-749c-405e-9526-9717641cc7de",
   "metadata": {},
   "source": [
    "### mini Code(Fill_HalfLife_Sheet): Fill t1/2 info into one Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "043723a6-be76-4ff7-815f-0b2c7b9158e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#============= Fill Half-Life to one sheet in Excel =============#\n",
    "def Fill_HalfLife_Sheet(txt_path, excel_path, sheet_name):\n",
    "    sheets = pd.read_excel(excel_path, sheet_name=None)  # Load all sheets\n",
    "    df = sheets[sheet_name]\n",
    "    # Add new columns for \"t1/2\" and \"unit\" if they don't already exist\n",
    "    if \"t1/2\" not in df.columns:\n",
    "        df[\"t1/2\"] = -1.0\n",
    "    df.at[df.index[-1], \"t1/2\"] = np.nan\n",
    "    if \"unit\" not in df.columns:\n",
    "        df[\"unit\"] = \"\"\n",
    "    if \"t1/2(s)\" not in df.columns:\n",
    "        df[\"t1/2(s)\"] = -1.0\n",
    "    df.at[df.index[-1], \"t1/2(s)\"] = np.nan\n",
    "    # Iterate over each entry in the extracted_data array\n",
    "\n",
    "    extracted_data = Extract_HalfLife(txt_path);\n",
    "    for data in extracted_data:\n",
    "        A = data[0]       # A\n",
    "        isotope = data[1] # \"Isotope\"\n",
    "        t_value = data[2] # t1/2\n",
    "        t_unit = data[3]  # \"unit\"\n",
    "        # Loop over all rows in the DataFrame to check for matches\n",
    "        for idx in range(len(df)-1):\n",
    "            if df.at[idx, \"A\"] == A and df.at[idx, \"isotope\"].lower() == isotope.lower():\n",
    "                # Fill the first matching row with t1/2 and unit data\n",
    "                if df.at[idx, \"t1/2\"] < 0:\n",
    "                    df.at[idx, \"t1/2\"] = t_value\n",
    "                    df.at[idx, \"unit\"] = t_unit\n",
    "                    df.at[idx, \"t1/2(s)\"] = t_value * HalfLife_Unit_Factor(t_unit)\n",
    "                    break\n",
    "                else:\n",
    "                    # If there are already values, create a new row\n",
    "                    new_row = df.loc[idx].copy()\n",
    "                    new_row[\"t1/2\"] = t_value\n",
    "                    new_row[\"unit\"] = t_unit\n",
    "                    new_row[\"t1/2(s)\"] = t_value * HalfLife_Unit_Factor(t_unit)\n",
    "                    # Append \" isomer\" to the Isotope in the new row\n",
    "                    new_row[\"isotope\"] = f\"{new_row['isotope']} isomer\"\n",
    "                    df = pd.concat([df.iloc[:idx + 1], pd.DataFrame([new_row]), df.iloc[idx + 1:]]).reset_index(drop=True)\n",
    "                    break\n",
    "    # Save df back to Excel\n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    # Reopen the workbook to apply formatting\n",
    "    workbook = load_workbook(excel_path)\n",
    "    # Set column width and alignment for the new sheet\n",
    "    worksheet = workbook[sheet_name]\n",
    "    for column in worksheet.columns:\n",
    "        column_letter = column[0].column_letter\n",
    "        worksheet.column_dimensions[column_letter].width = 16\n",
    "        for cell in column:  # Align each cell in the column\n",
    "            cell.alignment = Alignment(horizontal='right')\n",
    "    # Save the workbook\n",
    "    workbook.save(excel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808a2b4-07b6-4316-8a8a-128fa3de34b1",
   "metadata": {},
   "source": [
    "### Code(Fill_HalfLife_Exce): Fill t1/2 info to all sheets in Exxcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7bacbe8-9e33-4868-ab47-34603025bc5a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#========================== Fill Half-Life to all sheets (\"MeV\") in Excel =============================#\n",
    "def Fill_HalfLife_Excel(txt_path, excel_path):\n",
    "    # To check if txt file exists\n",
    "    if os.path.exists(txt_path) is False:\n",
    "        # Get the base name of the txt file (without the extension) using string operations\n",
    "        base_name = txt_path.split('/')[-1].replace('.txt', '')\n",
    "        # Create the output TXT file name\n",
    "        pdf_path = txt_path.replace('.txt', '.pdf')\n",
    "        Convert_PDF_to_TXT(pdf_path)\n",
    "    workbook = load_workbook(excel_path)\n",
    "    sheet_names = workbook.sheetnames   \n",
    "    # Iterate over all sheets and call Fill_HalfLife_Sheet() if the sheet name includes \"MeV\"\n",
    "    for sheet_name in sheet_names:\n",
    "        if \"MeV\" in sheet_name:\n",
    "            Fill_HalfLife_Sheet(txt_path, excel_path, sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cef4e9-0d1a-4da5-99b3-c3637768c034",
   "metadata": {},
   "source": [
    "## Step 5: Calculate Production Rate\n",
    "---\n",
    "1. Read information from Sheet \"Initial\"\n",
    "2. Calculate production rates in each sub Sheet\n",
    "\n",
    "* Be really really careful on unit, the current code is based on unit:\n",
    "  1. thickness: mg/cm2;\n",
    "  2. molar mass: g;\n",
    "  3. x-section: mb;\n",
    "  4. beam rate: pps;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccbe751-5ca5-4667-b3d5-4a0e47d92369",
   "metadata": {},
   "source": [
    "### Code(ReadInitial): Read Sheet \"Initial\":\n",
    "1. thickness in \"mg/cm2\";\n",
    "2. molar mass in \"g\"\n",
    "3. beam rate in \"pps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "194fbefd-0319-4311-b553-81b204bd4614",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def ReadInitial(excel_path):\n",
    "    sheets = pd.read_excel(excel_path, sheet_name=None)  # Load all sheets\n",
    "    df = sheets[\"Initial\"]\n",
    "    \n",
    "    # locate the target info\n",
    "    target_col_index = df.columns.get_loc('Target')\n",
    "    thick_row_idx = df[df.iloc[:, target_col_index + 2] == 'mg/cm2'].index[0]\n",
    "    thick_tot = df.iloc[thick_row_idx, target_col_index + 1]\n",
    "    mass_row_idx = df[df.iloc[:, target_col_index + 2] == 'g'].index[0]\n",
    "    mass = df.iloc[mass_row_idx, target_col_index + 1]\n",
    "\n",
    "    # locate the beam info\n",
    "    beam_col_index = df.columns.get_loc('Beam')\n",
    "    rate_row_idx = df[df.iloc[:, beam_col_index + 2] == 'pps'].index[0]\n",
    "    rate = df.iloc[rate_row_idx, beam_col_index + 1]\n",
    "\n",
    "    return thick_tot, mass, rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e131670-99ce-4c0c-96dd-481ac18598c9",
   "metadata": {},
   "source": [
    "### Code(Cal_Prodx_Rate): Calculate production rate in on Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dfe513a-955c-4310-a96a-00aedd148bfa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Cal_Prodx_Rate(df, NLayer, thick_tot, mass, rate):\n",
    "    if \"Prodx_Rate(pps)\" not in df.columns:\n",
    "        df[\"Prodx_Rate(pps)\"] = -1.0\n",
    "    df.at[df.index[-1], \"Prodx_Rate(pps)\"] = np.nan\n",
    "    for idx in range(len(df)-1):\n",
    "        xsec = df.at[idx,'x-section(mb)']\n",
    "        # Eqn: prodx_rate = xsec(m2) * unit_thick(g/m2) / mass(g) *rate (atom/s)\n",
    "        # 1 mb = 1e-3 barn = 1e-3 * 1e-28 m2\n",
    "        # 1 mg/cm2 = 10 g/m2\n",
    "        df.at[idx,'Prodx_Rate(pps)'] = (xsec/1e3/1e28)*((thick_tot/NLayer)*10)/mass*rate\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87bb2ad-151b-45a2-beb8-6637711868bf",
   "metadata": {},
   "source": [
    "### Code(Write_Prodx_Rate): Update all sheets in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74c2bd2b-9147-466e-9b12-2aa9e2694010",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Write_Prodx_Rate(excel_path, NLayer):\n",
    "    thick_tot, mass, rate = ReadInitial(excel_path)\n",
    "\n",
    "    sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "    workbook = load_workbook(excel_path)\n",
    "    sheet_names = workbook.sheetnames   \n",
    "    # Iterate over all sheets and call Fill_HalfLife_Sheet() if the sheet name includes \"MeV\"\n",
    "    for sheet_name in sheet_names:\n",
    "        if \"MeV\" in sheet_name:\n",
    "            df = sheets[sheet_name]\n",
    "            df = Cal_Prodx_Rate(df, NLayer, thick_tot, mass, rate)\n",
    "            # Save df back to Excel\n",
    "            with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            # Reopen the workbook to apply formatting\n",
    "            workbook = load_workbook(excel_path)\n",
    "            # Set column width and alignment for the new sheet\n",
    "            worksheet = workbook[sheet_name]\n",
    "            for column in worksheet.columns:\n",
    "                column_letter = column[0].column_letter\n",
    "                worksheet.column_dimensions[column_letter].width = 16\n",
    "                for cell in column:  # Align each cell in the column\n",
    "                    cell.alignment = Alignment(horizontal='right')\n",
    "            # Save the workbook\n",
    "            workbook.save(excel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100853c-83a3-4db3-8a73-d378de9a016a",
   "metadata": {},
   "source": [
    "## Step 6: Generate Stopping Ratio\n",
    "---\n",
    "1. Currently, set stopping ratios for all isotopes under all cases are 1, which means all productions will stop in the target;\n",
    "2. Generate values and save into Excel and create txt foils (optional, named with sub sheet name):\n",
    "\n",
    "+ ToDo:\n",
    "Either SRIM results or GEANT4 codes for thses values, based on recoil energy and the rest of thickness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c340dd-9f9b-4eb1-b460-e7b6eab8af30",
   "metadata": {},
   "source": [
    "### Code(Generate_Stop_Ratio):\n",
    "+ Default:\n",
    "+ Generate stopping ratio of all isotopes under all cases = 1;</br>\n",
    "+ Only update Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34072fb9-6a02-4b03-8b06-76ec1c13d5d3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Generate_Stop_Ratio(excel_path):\n",
    "    sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "    workbook = load_workbook(excel_path)\n",
    "    sheet_names = workbook.sheetnames\n",
    "    for sheet_name in sheet_names:\n",
    "        if \"MeV\" in sheet_name:\n",
    "            df = sheets[sheet_name]\n",
    "            if \"Stop_Ratio\" not in df.columns:\n",
    "                df[\"Stop_Ratio\"] = 1\n",
    "            else: \n",
    "                print(\"Stopping Ratio has been generated\")\n",
    "                return \n",
    "            df.at[df.index[-1], \"Stop_Ratio\"] = np.nan\n",
    "            with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            # Reopen the workbook to apply formatting\n",
    "            workbook = load_workbook(excel_path)\n",
    "            # Set column width and alignment for the new sheet\n",
    "            worksheet = workbook[sheet_name]\n",
    "            for column in worksheet.columns:\n",
    "                column_letter = column[0].column_letter\n",
    "                worksheet.column_dimensions[column_letter].width = 16\n",
    "            for cell in column:  # Align each cell in the column\n",
    "                cell.alignment = Alignment(horizontal='right')\n",
    "            # Save the workbook\n",
    "            workbook.save(excel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7562cd8d-cb8e-44b3-8de0-f66205845040",
   "metadata": {},
   "source": [
    "## Step 7: Calculate Production A(Bq) and Summarize Sub Sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb248fe-a3d0-4193-8188-fc3ee75af451",
   "metadata": {},
   "source": [
    "### 7.1: Calculate Production A(Bq):\n",
    "A = Prodx_Rate * (1-exp(-0.693/halflife * beam_time)) * Stop_Ratio\n",
    "+ Everything in the equation above is in seconds\n",
    "\n",
    "### Code(Cal_Prodx_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8032e1a0-9e96-4558-8933-fbfb20687d0e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Cal_Prodx_A(excel_path):\n",
    "    sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "    workbook = load_workbook(excel_path)\n",
    "    sheet_names = workbook.sheetnames\n",
    "\n",
    "    df = sheets[\"Initial\"]\n",
    "    beam_col_index = df.columns.get_loc('Beam')\n",
    "    run_time_row_idx = df[df.iloc[:, beam_col_index + 2] == 'sec'].index[0]\n",
    "    run_time = df.iloc[run_time_row_idx, beam_col_index + 1]\n",
    "\n",
    "    for sheet_name in sheet_names:\n",
    "        if \"MeV\" in sheet_name:\n",
    "            df = sheets[sheet_name]\n",
    "            if \"Prodx_A(Bq)\" not in df.columns:\n",
    "                df[\"Prodx_A(Bq)\"] = -1.0\n",
    "            df.at[df.index[-1], \"Prodx_A(Bq)\"] = np.nan\n",
    "            for idx in range(len(df)-1):\n",
    "                prodx_rate = df.at[idx,'Prodx_Rate(pps)']\n",
    "                halflife = df.at[idx,'t1/2(s)']\n",
    "                stop_ratio = df.at[idx,'Stop_Ratio']\n",
    "                df.at[idx,\"Prodx_A(Bq)\"] = prodx_rate * (1 - np.exp(-0.693/halflife * run_time)) * stop_ratio\n",
    "\n",
    "\n",
    "            # Save df back to Excel\n",
    "            with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            # Reopen the workbook to apply formatting\n",
    "            workbook = load_workbook(excel_path)\n",
    "            # Set column width and alignment for the new sheet\n",
    "            worksheet = workbook[sheet_name]\n",
    "            for column in worksheet.columns:\n",
    "                column_letter = column[0].column_letter\n",
    "                worksheet.column_dimensions[column_letter].width = 16\n",
    "                for cell in column:  # Align each cell in the column\n",
    "                    cell.alignment = Alignment(horizontal='right')\n",
    "            # Save the workbook\n",
    "            workbook.save(excel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e64a1-db60-4f2c-908c-ced1d89b954c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 7.2 Summarize all sub sheets (including A, isotope, A(Bq) @ *um)\n",
    "1. Summarize all production activities in one sheet;\n",
    "2. Calculate sum activity of each production at cool down time = 0s;\n",
    "3. (optional) Delete production row if A = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a487acb7-72f2-4776-93d8-253651163dc3",
   "metadata": {},
   "source": [
    "### Code(summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f149413b-6aa1-4d5f-9d54-6a6f42a896a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def summarize(excel_path, clean_table = True):\n",
    "    sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "    workbook = load_workbook(excel_path)\n",
    "\n",
    "    # Extract data from sheets named \"*um_*MeV\"\n",
    "    data_frames = []\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        if 'um_' in sheet_name and 'MeV' in sheet_name:\n",
    "            df = sheets[sheet_name][['A', 'isotope', 'Prodx_A(Bq)']]\n",
    "            df.columns = ['A', 'isotope', f'A(Bq)@{sheet_name.split(\"um_\")[0]}um']\n",
    "            data_frames.append((int(sheet_name.split('um_')[0]), df))\n",
    "\n",
    "    # Sort data_frames by the numeric value in the sheet names\n",
    "    data_frames.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Extract only the DataFrames in the correct order\n",
    "    data_frames = [df for _, df in data_frames]\n",
    "\n",
    "    # Merge all data frames on 'A' and 'isotope'\n",
    "    merged_df = data_frames[0]\n",
    "    for df in data_frames[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on=['A', 'isotope'], how='outer')\n",
    "\n",
    "    # Reorder by \"A\" from large to small, and then by \"isotope\" keyword\n",
    "    merged_df['isotope_keyword'] = merged_df['isotope'].str.replace(' isomer', '')\n",
    "    merged_df = merged_df.sort_values(by=['A', 'isotope_keyword', 'isotope'], ascending=[False, True, True])\n",
    "    # Drop the temporary column used for sorting\n",
    "    merged_df = merged_df.drop(columns=['isotope_keyword'])\n",
    "    \n",
    "    # Round all \"Prodx\" columns to 2 decimal places\n",
    "    for col in merged_df.columns:\n",
    "        if \"um\" in col:\n",
    "            merged_df[col] = merged_df[col].fillna(0).round(2)\n",
    "\n",
    "    # Add the new column \"A(Bq)@cd = 0s\" if it doesn't exist\n",
    "    if \"A(Bq)@cd = 0s\" not in merged_df.columns:\n",
    "        merged_df[\"A(Bq)@cd = 0s\"] = -1\n",
    "\n",
    "    # Calculate the sum of all \"A(Bq)@*um\" columns for each row\n",
    "    sum_columns = [col for col in merged_df.columns if \"um\" in col]\n",
    "    merged_df[\"A(Bq)@cd = 0s\"] = merged_df[sum_columns].sum(axis=1)\n",
    "\n",
    "    # Remove rows where \"A(Bq)@cd = 0s\" is 0\n",
    "    if clean_table:\n",
    "        merged_df = merged_df[merged_df[\"A(Bq)@cd = 0s\"] != 0]\n",
    "    \n",
    "    # Save the updated workbook\n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists = 'replace') as writer:\n",
    "        merged_df.to_excel(writer, sheet_name='Summary_A', index=False)\n",
    "\n",
    "    # Reopen the workbook to apply formatting\n",
    "    workbook = load_workbook(excel_path)\n",
    "    # Set column width and alignment for the new sheet\n",
    "    worksheet = workbook['Summary_A']\n",
    "    for column in worksheet.columns:\n",
    "        column_letter = column[0].column_letter\n",
    "        worksheet.column_dimensions[column_letter].width = 14\n",
    "        for cell in column:  # Align each cell in the column\n",
    "            cell.alignment = Alignment(horizontal='right')\n",
    "            # Save the workbook\n",
    "    workbook.save(excel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde973e4-893c-4770-a579-680d53a90d67",
   "metadata": {},
   "source": [
    "## Test!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc9ff104-7a98-44e1-9ff3-2286e51b3e6e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "excel_path = \"DoesCal.xlsx\" # Initial Fill after Step 1\n",
    "pace4_path = \"PACE4/\" # It is a folder containing all PDF of PACE4 results after Step 2\n",
    "\n",
    "# Update PACE4 results to Excels (Codes in Step 3)\n",
    "RWPACE4(pace4_path, excel_path)\n",
    "\n",
    "t_path = \"HalfLife/Levels_Results.txt\" \n",
    "# Fill t1/2 info in to Excel (Codes in Step 4.2)\n",
    "Fill_HalfLife_Excel(t_path, excel_path)\n",
    "\n",
    "# Calculate production rates in sheet \"..MeV\"\n",
    "# In this example, 15um target foil is separated by 5 layers. Each layer is 3um;\n",
    "NLayer = 5\n",
    "Write_Prodx_Rate(excel_path, NLayer) \n",
    "\n",
    "# Generate Stopping Ratio (Step 6)\n",
    "Generate_Stop_Ratio(excel_path)\n",
    "\n",
    "# Calculate Production Acitivity at cd = 0 s (Step 7.1)\n",
    "Cal_Prodx_A(excel_path)\n",
    "\n",
    "# Summarize Production info so far to a new sheet \"Summary\" (Step 7.2)\n",
    "summarize(excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48cc1a7-0508-4034-b206-6e5ca54c16e2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
