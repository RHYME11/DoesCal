{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e262dd4e-856e-493a-abbe-9df623db412a",
   "metadata": {},
   "source": [
    "## Convert Irradiation PDF to TXT and based on values to calculate Hp\n",
    "---\n",
    "It will be similar to half-life search, but I don't "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3aab82e-f36f-411e-a322-d83bb077c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdfplumber\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Font, PatternFill, Border, Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badce950-b85e-4deb-8590-7d9c5dc66769",
   "metadata": {},
   "source": [
    "### Specific for Otto_2016.pdf"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15a28606-9edb-4e62-851d-20fbcc431d47",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "with pdfplumber.open(\"/Users/yiyizhu/Packages/DoesCal/example/Otto_2016.pdf\") as pdf:\n",
    "    for index, page in enumerate(pdf.pages):\n",
    "        if index >= 6 and index <=7:\n",
    "            text = page.extract_text()\n",
    "            print(f\"page{index}: {text}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a878655e-399f-4bfe-98de-7299d084c092",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "with pdfplumber.open(\"/Users/yiyizhu/Packages/DoesCal/example/Otto_2016.pdf\") as pdf:\n",
    "    for index, page in enumerate(pdf.pages):\n",
    "        if index >= 6 and index <= 36:\n",
    "            print(f\"\\n\\npage {index+1}\")\n",
    "            text = page.extract_text()\n",
    "            lines = text.split('\\n')\n",
    "            for i, line in enumerate(lines):\n",
    "                if bool(re.match(r'^\\d+[A-Za-z]', line.split()[0])):\n",
    "                    print(f\"{line.split()}\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d7d6866-d256-410b-940b-9545ac9f1f8b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "# Specific format for \"Otto\"\n",
    "txt = [[\"#\", \"unit:\", \"uSv/h/GBq\"],\n",
    "       [\"A\", \"isotope\", \"Hp10_100cm_unshield\", \"Hp10_100cm_shield\", \"Hp07_10cm_unshield\", \"Hp07_10cm_shield\"]]\n",
    "\n",
    "with pdfplumber.open(\"/Users/yiyizhu/Packages/DoesCal/example/DoesPar/Otto_2016.pdf\") as pdf:\n",
    "    for index, page in enumerate(pdf.pages):\n",
    "        # page reuiqrement\n",
    "        if index >= 6 and index <= 36:\n",
    "        #if index == 6:\n",
    "            text = page.extract_text()\n",
    "            lines = text.split('\\n')\n",
    "            # loop lines in one page\n",
    "            for i, line in enumerate(lines):\n",
    "                # line.split() to split one line into multiple strings by space or tab\n",
    "                if bool(re.match(r'^\\d+[A-Za-z]', line.split()[0])):\n",
    "                    letters_only = ''.join(re.findall(r'[A-Za-z]+', line.split()[0]))\n",
    "                    if letters_only.startswith('m'):\n",
    "                        letters_only = letters_only[1:] + \"_isomer\"\n",
    "                    new_row = [int(line.split()[2]), \n",
    "                               letters_only,\n",
    "                               float(line.split()[5]),\n",
    "                               float(line.split()[6]),\n",
    "                               float(line.split()[9])/1000.,   # /1000 convert unit from mSv to uSv\n",
    "                               float(line.split()[10])/1000.]  # /1000 convert unit from mSv to uSv\n",
    "                    txt.append(new_row)\n",
    "\n",
    "txt_path = \"example/DoesPar/DoesPar_Otto.txt\"\n",
    "with open(txt_path, \"w\") as output_file:\n",
    "    for row in txt:\n",
    "        output_file.write(\"\\t\".join(map(str, row)) + \"\\n\")                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c0d6c-3a13-45ae-b75a-9255e2f97dff",
   "metadata": {},
   "source": [
    "#### Here is the code for Otto_2016.pdf. Convert Tabel 2 to 4 txt files.\n",
    "* (Change it to \"Code\", and run it.)\n",
    "* Includes 4 information:\n",
    "  1. Hp10_100cm_shield;\n",
    "  2. Hp10_100cm_unshield\n",
    "  3. Hp07_10cm_shield\n",
    "  4. Hp07_10cm_unshield"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c510bb3f-1962-4485-9d6e-095a062afdc8",
   "metadata": {},
   "source": [
    "# Specific format for \"Otto\"\n",
    "txt_hp10_100cm_unshield = [ [\"# From Thomas Otto 2016\"],\n",
    "                            [\"#\", \"unit:\", \"uSv/h/GBq\"],\n",
    "                            [\"#A\", \"isotope\", \"Hp10_100cm_unshield\"]]\n",
    "txt_hp10_100cm_shield = [   [\"# From Thomas Otto 2016\"],\n",
    "                            [\"#\", \"unit:\", \"uSv/h/GBq\"],\n",
    "                            [\"#A\", \"isotope\", \"Hp10_100cm_shield\"]]\n",
    "txt_hp07_10cm_unshield = [  [\"# From Thomas Otto 2016\"],\n",
    "                            [\"#\", \"unit:\", \"uSv/h/GBq\"],\n",
    "                            [\"#A\", \"isotope\", \"Hp07_10cm_unshield\"]]\n",
    "txt_hp07_10cm_shield = [    [\"# From Thomas Otto 2016\"],\n",
    "                            [\"#\", \"unit:\", \"uSv/h/GBq\"],\n",
    "                            [\"#A\", \"isotope\", \"Hp07_10cm_shield\"]]\n",
    "\n",
    "\n",
    "with pdfplumber.open(\"/Users/yiyizhu/Packages/DoesCal/example/DoesPar/Otto_2016.pdf\") as pdf:\n",
    "    for index, page in enumerate(pdf.pages):\n",
    "        # page reuiqrement\n",
    "        if index >= 6 and index <= 36:\n",
    "        #if index == 6:\n",
    "            text = page.extract_text()\n",
    "            lines = text.split('\\n')\n",
    "            # loop lines in one page\n",
    "            for i, line in enumerate(lines):\n",
    "                # line.split() to split one line into multiple strings by space or tab\n",
    "                if bool(re.match(r'^\\d+[A-Za-z]', line.split()[0])):\n",
    "                    letters_only = ''.join(re.findall(r'[A-Za-z]+', line.split()[0]))\n",
    "                    if letters_only.startswith('m'):\n",
    "                        letters_only = letters_only[1:] + \"_isomer\"\n",
    "                    A = int(line.split()[2])\n",
    "                    isotope = letters_only\n",
    "                    hp10_100cm_unshield = round(float(line.split()[5]), 2)\n",
    "                    hp10_100cm_shield = round(float(line.split()[6]), 2)\n",
    "                    hp07_10cm_unshield = round(float(line.split()[9])*1000., 2)   # *1000 convert unit from mSv to uSv\n",
    "                    hp07_10cm_shield = round(float(line.split()[10])*1000., 2)  # *1000 convert unit from mSv to uSv\n",
    "                    # Append each row to the respective list\n",
    "                    txt_hp10_100cm_unshield.append([A, isotope, hp10_100cm_unshield])\n",
    "                    txt_hp10_100cm_shield.append([A, isotope, hp10_100cm_shield])\n",
    "                    txt_hp07_10cm_unshield.append([A, isotope, hp07_10cm_unshield])\n",
    "                    txt_hp07_10cm_shield.append([A, isotope, hp07_10cm_shield])\n",
    "\n",
    "# Define file paths for each output txt file\n",
    "def format_row(row):\n",
    "    # Check if the row has at least 3 elements before formatting\n",
    "    if len(row) >= 3:\n",
    "        return \"{:<5} {:<10} {:>15}\".format(row[0], row[1], row[2])\n",
    "    else:\n",
    "        return \"\"  # Return an empty string if the row doesn't have enough elements\n",
    "# Define file paths for each output txt file\n",
    "file_paths = {\n",
    "    \"Hp10_100cm_unshield\": txt_hp10_100cm_unshield,\n",
    "    \"Hp10_100cm_shield\": txt_hp10_100cm_shield,\n",
    "    \"Hp07_10cm_unshield\": txt_hp07_10cm_unshield,\n",
    "    \"Hp07_10cm_shield\": txt_hp07_10cm_shield,\n",
    "}\n",
    "\n",
    "# Write each list to its respective text file\n",
    "for file_name, data in file_paths.items():\n",
    "    with open(f\"example/DoesPar/{file_name}_Otto2016.txt\", \"w\") as output_file:\n",
    "        for row in data:\n",
    "            formatted_row = format_row(row)\n",
    "            if formatted_row:  # Only write non-empty rows\n",
    "                output_file.write(formatted_row + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2260597b-8851-4b5b-a212-3d2a22f9ca93",
   "metadata": {},
   "source": [
    "### Specific for RPO 814.501"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02250243-fa64-4dd2-8eb7-194df5291331",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "with pdfplumber.open(\"/Users/yiyizhu/Packages/DoesCal/example/DoesPar/814.501.2014.pdf\") as pdf:\n",
    "    for index, page in enumerate(pdf.pages):\n",
    "        #if index >= 64 and index <= 93:\n",
    "        if index >= 64 and index <= 65:\n",
    "            #print(f\"\\n\\npage {index+1}\")\n",
    "            text = page.extract_text()\n",
    "            lines = text.split('\\n')\n",
    "            for i, line in enumerate(lines):\n",
    "                if bool(re.match(r\"^[A-Za-z]+-\\d+(\\/[A-Za-z]+-\\d+)*,?$\", line.split()[0])):\n",
    "                    print(f\"{line.split()}\")\n",
    "                #if bool(re.match(r\"^[A-Za-z]+-\\d+$\", line.split()[0])):\n",
    "                #    print(f\"{line.split()[0]} {line.split()[1]} {line.split()[2]} {line.split()[3]}type={type(line.split()[3])}, length = {len(line.split())}\")\n",
    "                #elif bool(re.match(r\"^[A-Za-z]+-\\d+(\\/[A-Za-z]+-\\d+)*,?$\", line.split()[0])):\n",
    "                #    print(f\"{line.split()[0]} {line.split()[1]} {line.split()[2]} {line.split()[3]} {line.split()[4]}type={type(line.split()[4])}, length = {len(line.split())}\")\n",
    "                "
   ]
  },
  {
   "cell_type": "raw",
   "id": "18c9fc93-8aea-41fe-9219-a59b87f2ee7d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "source": [
    "with pdfplumber.open('/Users/yiyizhu/Packages/DoesCal/example/DoesPar/814.501.2014.pdf') as pdf:\n",
    "    # Load the specific page (page 65 in this case)\n",
    "    page = pdf.pages[64]  # Page indexing starts from 0\n",
    "    # Extract the raw text\n",
    "    text = page.extract_text()\n",
    "\n",
    "# Split the text into lines\n",
    "lines = text.split('\\n')\n",
    "\n",
    "# Initialize a list to hold the data\n",
    "table_data = []\n",
    "\n",
    "# Loop through the lines to find relevant rows\n",
    "for line in lines:\n",
    "    # Split the line by spaces to separate columns\n",
    "    columns = line.split()\n",
    "\n",
    "    if columns and re.match(r'^[A-Za-z]+-\\d+', columns[0]):\n",
    "        nuclide = columns[0]  # Nuclide\n",
    "        if '/' in nuclide:\n",
    "            isotopes = nuclide.split('/')\n",
    "            for isotope in isotopes:\n",
    "                number, letter = process_nuclide(isotope)\n",
    "                # Add the rest of the data\n",
    "                new_row = [number, letter] + columns[1:]\n",
    "                table_data.append(new_row)\n",
    "        else:\n",
    "            number, letter = process_nuclide(nuclide)\n",
    "            if columns[1].isalpha():\n",
    "                letter += f\"_{columns[1]}\"\n",
    "                new_row = [number, letter] + columns[2:]\n",
    "            else:\n",
    "                new_row = [number, letter] + columns[1:]\n",
    "            table_data.append(new_row)\n",
    "\n",
    "# Display the extracted 2D array\n",
    "for entry in table_data:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce793ca0-61cd-4199-a948-e8307741e4bf",
   "metadata": {},
   "source": [
    "#### Mini Code (process_nuclide) to edit \"32-Clm\" to '32',\"Cl_isomer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5cd3a2a-f6b0-40c6-9f2c-f978b4328f46",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to split nuclide and handle isomers\n",
    "def process_nuclide(nuclide):\n",
    "    # Check if it's an isomer\n",
    "    if 'm' in nuclide:\n",
    "        parts = re.split(r'[-m]', nuclide)  # Split by hyphen or 'm'\n",
    "        number = parts[1]\n",
    "        letter = parts[0] + \"_isomer\"\n",
    "    else:\n",
    "        parts = nuclide.split('-')\n",
    "        number = parts[1]\n",
    "        letter = parts[0]\n",
    "    return number, letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b2701d-e2e4-421f-b467-c644bd639c2b",
   "metadata": {},
   "source": [
    "#### Mini Code (combine_scientific_notation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82b28d8d-824d-45b9-85ae-2baca8e51d91",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to combine number and scientific notation\n",
    "def combine_scientific_notation(columns):\n",
    "    combined = []\n",
    "    skip = False\n",
    "    for i in range(len(columns) - 1):\n",
    "        if skip:\n",
    "            skip = False\n",
    "            continue\n",
    "        # Check if the current element is a number and the next element is in scientific notation\n",
    "        if re.match(r'^\\d+(\\.\\d+)?$', columns[i]) and re.match(r'^E[+-]\\d+$', columns[i + 1]):\n",
    "            combined.append(f\"{columns[i]}e{columns[i + 1][1:]}\")\n",
    "            skip = True  # Skip the next element because we've combined it\n",
    "        else:\n",
    "            combined.append(columns[i])\n",
    "    if not skip:\n",
    "        combined.append(columns[-1])  # Append the last element if it wasn't part of a pair\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a41c53ab-2e8f-42eb-a0df-7f1a1498c6e0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "with pdfplumber.open('/Users/yiyizhu/Packages/DoesCal/example/DoesPar/814.501.2014.pdf') as pdf:\n",
    "    # Load the specific page (page 65 in this case)\n",
    "    page = pdf.pages[65]  # Page indexing starts from 0\n",
    "    # Extract the raw text\n",
    "    text = page.extract_text()\n",
    "\n",
    "# Split the text into lines\n",
    "lines = text.split('\\n')\n",
    "\n",
    "# Initialize a list to hold the data\n",
    "table_data = []\n",
    "\n",
    "# Loop through the lines to find relevant rows\n",
    "for line in lines:\n",
    "    # Split the line by spaces to separate columns\n",
    "    columns = line.split()\n",
    "\n",
    "    if columns and re.match(r'^[A-Za-z]+-\\d+', columns[0]):\n",
    "        # Basic check to ensure there are enough columns\n",
    "        if len(columns) > 5:\n",
    "            nuclide = columns[0]  # Nuclide\n",
    "            if '/' in nuclide:\n",
    "                isotopes = nuclide.split('/')\n",
    "                for isotope in isotopes:\n",
    "                    number, letter = process_nuclide(isotope)\n",
    "                    # Add the rest of the data\n",
    "                    new_row = [number, letter] + combine_scientific_notation(columns[1:10])\n",
    "                    table_data.append(new_row)\n",
    "            else:\n",
    "                number, letter = process_nuclide(nuclide)\n",
    "                if columns[1].isalpha():\n",
    "                    letter += f\"_{columns[1]}\"\n",
    "                    new_row = [number, letter] + combine_scientific_notation(columns[2:11])\n",
    "                else:\n",
    "                    new_row = [number, letter] + combine_scientific_notation(columns[1:11])\n",
    "                table_data.append(new_row)\n",
    "\n",
    "# Display the extracted 2D array\n",
    "for entry in table_data:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b7e5348-301d-4bb7-b14b-09dc94ad00e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "with pdfplumber.open('/Users/yiyizhu/Packages/DoesCal/example/DoesPar/814.501.2014.pdf') as pdf:\n",
    "    # Load the specific page (page 65 in this case)\n",
    "    page = pdf.pages[64]  # Page indexing starts from 0\n",
    "    # Extract the raw text\n",
    "    text = page.extract_text()\n",
    "\n",
    "# Split the text into lines\n",
    "lines = text.split('\\n')\n",
    "\n",
    "# Initialize a list to hold the data\n",
    "table_data = []\n",
    "\n",
    "# Loop through the lines to find relevant rows\n",
    "for line in lines:\n",
    "    # Split the line by spaces to separate columns\n",
    "    columns = line.split()\n",
    "\n",
    "    if columns and re.match(r'^[A-Za-z]+-\\d+', columns[0]):\n",
    "        # Basic check to ensure there are enough columns\n",
    "        if len(columns) > 5:\n",
    "            nuclide = columns[0]  # Nuclide\n",
    "            if '/' in nuclide:\n",
    "                isotopes = nuclide.split('/')\n",
    "                for isotope in isotopes:\n",
    "                    number, letter = process_nuclide(isotope)\n",
    "                    # Add the rest of the data\n",
    "                    new_row = [number, letter] + combine_scientific_notation(columns[1:10])\n",
    "                    table_data.append(new_row)\n",
    "            else:\n",
    "                number, letter = process_nuclide(nuclide)\n",
    "                if columns[1].isalpha():\n",
    "                    letter += f\"_{columns[1]}\"\n",
    "                    new_row = [number, letter] + combine_scientific_notation(columns[2:11])\n",
    "                else:\n",
    "                    new_row = [number, letter] + combine_scientific_notation(columns[1:11])\n",
    "                table_data.append(new_row)\n",
    "\n",
    "# Now filter the rows based on your conditions\n",
    "final_data = []\n",
    "\n",
    "for row in table_data:\n",
    "    # Find the index of the unicode marker (example '\\uf062\\uf02d\\uf020' or other)\n",
    "    unicode_index = -1\n",
    "    for i, val in enumerate(row):\n",
    "        if repr(val).startswith(\"'\\\\u\"):  # Check if the element is a Unicode character\n",
    "            unicode_index = i\n",
    "        \n",
    "    # Proceed if a Unicode element was found\n",
    "    if unicode_index != -1 and unicode_index + 2 < len(row):\n",
    "        try:\n",
    "            # Extract the second element after the Unicode character\n",
    "            second_value_after_unicode = float(row[unicode_index + 2].replace('<', ''))\n",
    "            \n",
    "            # Only keep rows where the second value after Unicode is <= 1e-4\n",
    "            if second_value_after_unicode < 1e-3:\n",
    "                final_data.append([row[0], row[1], row[unicode_index + 2]])  # Keep the second value after Unicode\n",
    "        except ValueError:\n",
    "            # If conversion to float fails, skip this row\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the extracted 2D array\n",
    "for entry in final_data:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53236516-1333-4495-85e8-e3f4eaac71eb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "source": [
    "# Initialize a list to hold the data\n",
    "table_data = []\n",
    "with pdfplumber.open('/Users/yiyizhu/Packages/DoesCal/example/DoesPar/814.501.2014.pdf') as pdf:\n",
    "    for page_num in range(64, 94): \n",
    "        page = pdf.pages[page_num]\n",
    "        text = page.extract_text()\n",
    "        lines = text.split('\\n')\n",
    "\n",
    "\n",
    "\n",
    "        # Loop through the lines to find relevant rows\n",
    "        for line in lines:\n",
    "            # Split the line by spaces to separate columns\n",
    "            columns = line.split()\n",
    "\n",
    "            if columns and re.match(r'^[A-Za-z]+-\\d+', columns[0]):\n",
    "                # Basic check to ensure there are enough columns\n",
    "                if len(columns) > 5:\n",
    "                    nuclide = columns[0]  # Nuclide\n",
    "                    if '/' in nuclide:\n",
    "                        isotopes = nuclide.split('/')\n",
    "                        for isotope in isotopes:\n",
    "                            number, letter = process_nuclide(isotope)\n",
    "                            # Add the rest of the data\n",
    "                            new_row = [number, letter] + combine_scientific_notation(columns[1:10])\n",
    "                            table_data.append(new_row)\n",
    "                    else:\n",
    "                        number, letter = process_nuclide(nuclide)\n",
    "                        if columns[1].isalpha():\n",
    "                            letter += f\"_{columns[1]}\"\n",
    "                            new_row = [number, letter] + combine_scientific_notation(columns[2:11])\n",
    "                        else:\n",
    "                            new_row = [number, letter] + combine_scientific_notation(columns[1:11])\n",
    "                        table_data.append(new_row)\n",
    "\n",
    "# Now filter the rows based on your conditions\n",
    "final_data = []\n",
    "\n",
    "for row in table_data:\n",
    "    # Find the index of the unicode marker (example '\\uf062\\uf02d\\uf020' or other)\n",
    "    unicode_index = -1\n",
    "    for i, val in enumerate(row):\n",
    "        if repr(val).startswith(\"'\\\\u\"):  # Check if the element is a Unicode character\n",
    "            unicode_index = i\n",
    "        \n",
    "    # Proceed if a Unicode element was found\n",
    "    if unicode_index != -1 and unicode_index + 2 < len(row):\n",
    "        try:\n",
    "            # Extract the second element after the Unicode character\n",
    "            second_value_after_unicode = float(row[unicode_index + 2].replace('<', ''))\n",
    "            \n",
    "            # Only keep rows where the second value after Unicode is <= 1e-4\n",
    "            if second_value_after_unicode < 1e-3:\n",
    "                final_data.append([row[0], row[1], row[unicode_index + 2]])  # Keep the second value after Unicode\n",
    "        except ValueError:\n",
    "            # If conversion to float fails, skip this row\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the extracted 2D array\n",
    "for entry in final_data:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4a54b-a0b7-41d6-8b10-34d0f0d20288",
   "metadata": {},
   "source": [
    "#### Here is the code for PRO 814.501 Tabel \"Data for Operational Radiation Protection\"\n",
    "* Only extract e_ing and convert it unit to uSv/GBq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44f08ad7-7cc0-4997-966b-00ae18f56847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to hold the data\n",
    "table_data = []\n",
    "with pdfplumber.open('/Users/yiyizhu/Packages/DoesCal/example/DoesPar/814.501.2014.pdf') as pdf:\n",
    "    for page_num in range(64, 94): \n",
    "        page = pdf.pages[page_num]\n",
    "        text = page.extract_text()\n",
    "        lines = text.split('\\n')\n",
    "\n",
    "\n",
    "\n",
    "        # Loop through the lines to find relevant rows\n",
    "        for line in lines:\n",
    "            # Split the line by spaces to separate columns\n",
    "            columns = line.split()\n",
    "\n",
    "            if columns and re.match(r'^[A-Za-z]+-\\d+', columns[0]):\n",
    "                # Basic check to ensure there are enough columns\n",
    "                if len(columns) > 5:\n",
    "                    nuclide = columns[0]  # Nuclide\n",
    "                    if '/' in nuclide:\n",
    "                        isotopes = nuclide.split('/')\n",
    "                        for isotope in isotopes:\n",
    "                            number, letter = process_nuclide(isotope)\n",
    "                            # Add the rest of the data\n",
    "                            new_row = [number, letter] + combine_scientific_notation(columns[1:10])\n",
    "                            table_data.append(new_row)\n",
    "                    else:\n",
    "                        number, letter = process_nuclide(nuclide)\n",
    "                        if columns[1].isalpha():\n",
    "                            letter += f\"_{columns[1]}\"\n",
    "                            new_row = [number, letter] + combine_scientific_notation(columns[2:11])\n",
    "                        else:\n",
    "                            new_row = [number, letter] + combine_scientific_notation(columns[1:11])\n",
    "                        table_data.append(new_row)\n",
    "\n",
    "# Now filter the rows based on your conditions\n",
    "final_data = [[\"# From RBO 814.501.2014\"],\n",
    "              [\"#\", \"unit:\", \"uSv/h/GBq\"],\n",
    "              [\"#A\", \"isotope\", \"e_ing\"]]\n",
    "\n",
    "for row in table_data:\n",
    "    # Find the index of the unicode marker (example '\\uf062\\uf02d\\uf020' or other)\n",
    "    unicode_index = -1\n",
    "    for i, val in enumerate(row):\n",
    "        if repr(val).startswith(\"'\\\\u\"):  # Check if the element is a Unicode character\n",
    "            unicode_index = i\n",
    "        \n",
    "    # Proceed if a Unicode element was found\n",
    "    if unicode_index != -1 and unicode_index + 2 < len(row):\n",
    "        try:\n",
    "            # Extract the second element after the Unicode character\n",
    "            second_value_after_unicode = float(row[unicode_index + 2].replace('<', ''))\n",
    "            \n",
    "            # Only keep rows where the second value after Unicode is <= 1e-4\n",
    "            if second_value_after_unicode < 1e-3:\n",
    "                second_value_after_unicode = second_value_after_unicode/1e3 # Convert Sv/Bq to uSv/GBq\n",
    "                final_data.append([row[0], row[1], row[unicode_index + 2]])  # Keep the second value after Unicode\n",
    "        except ValueError:\n",
    "            # If conversion to float fails, skip this row\n",
    "            continue\n",
    "\n",
    "\n",
    "# Define file paths for each output txt file\n",
    "def format_row(row):\n",
    "    # Check if the row has at least 3 elements before formatting\n",
    "    if len(row) >= 3:\n",
    "        return \"{:<5} {:<10} {:>15}\".format(row[0], row[1], row[2])\n",
    "    else:\n",
    "        return \"\"  # Return an empty string if the row doesn't have enough elements\n",
    "\n",
    "# Write the final_data to a txt file\n",
    "output_file_path = \"example/DoesPar/PRO_814_501.txt\"\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    for row in final_data:\n",
    "        formatted_row = format_row(row)\n",
    "        if formatted_row:  # Only write non-empty rows\n",
    "            output_file.write(formatted_row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f33bd-0a01-4533-8cce-91d5f35278f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
